What is the main difference between NoSQL databases and traditional relational databases?

  * Traditional Relational database, data stored in a structured way and we can call this data using queries. User could find relation between information. 
  NoSQL databases, on the other hand, store data in an unstructured way, often as key-value pairs or JSON-like documents, 
  and do not have the same relational capabilities as traditional relational databases.
  
What is the main advantage of using a key-value store over other types of NoSQL databases?

  * Key-value stores are simple, fast and horizontally scalable making them ideal for handling large amounts of data and high traffic with minimal latency.
  
Can you explain what sharding is and how it works in MongoDB?
  
  * Sharding is a way to split a database into smaller parts called shards, which are stored on different servers. 
  This allows the database to handle more data and handle more requests. MongoDB uses sharding to divide the data in the database based on a certain key, this way when a request is made, it knows which shard to look in for the requested data. 
  This improves the performance of the database and allows it to scale horizontally. 
  
How does a graph database differ from a traditional relational database in terms of how it stores and retrieves data?
  
   * A graph database stores data as nodes and edges, representing entities and their relationships, while a relational database stores data in tables with rows and columns. 
   A graph database uses traversals to retrieve data by following relationships, while a relational database uses SQL to retrieve data based on table structures.
   Graph databases are more suitable for complex and dynamic relationships, and can handle unstructured data better.
   
What is the main benefit of using a graph database over a relational database for certain types of data?

  * A relational database stores data in tables, like a spreadsheet, and uses relationships (like links or keys) to connect data in different tables. 
    This is good for structured data with a clear schema.
    
Map Reduce,

 MapReduce is a programming model and an associated implementation for processing and generating large data sets in a distributed computing environment. It was first introduced by Google in a research paper in 2004. The idea behind MapReduce was to provide a simple and powerful abstraction for processing large data sets in parallel across a cluster of machines.

MapReduce consists of two main operations: the map operation and the reduce operation. The map operation takes an input dataset and applies a function to each element, producing a set of intermediate key-value pairs. The reduce operation takes the intermediate key-value pairs and combines them together based on the key, producing a set of output key-value pairs. The process of shuffling and sorting is done in between the map and reduce operations, which allows for more efficient data processing.

MapReduce was designed to be a simple and general-purpose programming model, which could be applied to a wide range of big data processing tasks. This simplicity and versatility have made it a popular choice for processing large datasets in many fields such as finance, social media, and e-commerce.

In recent years, many alternative frameworks have been developed to address some of the limitations of MapReduce, such as, the lack of support for real-time processing, and the need for more sophisticated data processing capabilities. However, MapReduce remains a widely used and powerful tool for processing large data sets in a distributed computing environment.

